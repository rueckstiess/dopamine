Testing Agent class from agents.agent
=====================================================================

Create dummy conditions and initialize agent
---------------------------------------------------------------------
>>> conditions = {'stateDim':3, 'actionDim':4}
>>> from dopamine.agents import Agent
>>> a = Agent()
>>> a._setup(conditions)
>>> a.conditions
{'stateDim': 3, 'actionDim': 4}
>>> len(a.history)
0
>>> a.episode
>>> a.progressCnt
0


Test state, action, reward cycle of agent
---------------------------------------------------------------------
>>> a.integrateState([1, 2, 3])
>>> a.progressCnt
1
>>> a.state
[1, 2, 3]
>>> a.action
>>> a.integrateState([1, 2, 3])
Traceback (most recent call last):
	...
AgentException: observation was given twice before action was requested.

>>> a.getAction()
array([ 0.,  0.,  0.,  0.])
>>> a.getAction()
Traceback (most recent call last):
	...
AgentException: action was requested after reward was given.

>>> a.progressCnt
2
>>> a.giveReward(-4)
>>> a.progressCnt
0


Test history and episode properties
---------------------------------------------------------------------
>>> print a.history
[ 1.  2.  3.][ 0.  0.  0.  0.] -4.0
>>> print a.episode
[ 1.  2.  3.][ 0.  0.  0.  0.] -4.0
>>> a.integrateState([4, 5, 6])
>>> a.getAction()
array([ 0.,  0.,  0.,  0.])
>>> a.giveReward(-2)
>>> print a.episode
[ 1.  2.  3.][ 0.  0.  0.  0.] -4.0
[ 4.  5.  6.][ 0.  0.  0.  0.] -2.0
>>> a.newEpisode()
>>> len(a.history)
1
>>> a.integrateState([7, 8, 9])
>>> a.getAction()
array([ 0.,  0.,  0.,  0.])
>>> a.giveReward(-1.5)
>>> print a.history
[ 1.  2.  3.][ 0.  0.  0.  0.] -4.0
[ 4.  5.  6.][ 0.  0.  0.  0.] -2.0
<BLANKLINE>
[ 7.  8.  9.][ 0.  0.  0.  0.] -1.5
>>> print a.episode
[ 7.  8.  9.][ 0.  0.  0.  0.] -1.5
>>> len(a.history)
2
>>> len(a.episode)
1
